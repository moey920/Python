## 코로나 날짜별 확진자 크롤링하기

## 모듈화에 집중하여 이용해보기.
```
# 네이버 증권에서 원하는 항목의 주가를 파싱해봅시다.
import time
from random import randint # 서버에 주기적으로 요청하면, ip를 막아버리는 경우가 생겨서 random 모듈을 이용한다.
import requests
from bs4 import BeautifulSoup


def parse_stock(company_code) :

    headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.368'}
    url = "https://finance.naver.com/item/main.nhn?code=" + company_code  # SAMSUNG
    
    response = requests.get(url, headers=headers)
    if response.status_code != 200 :
        return print("Unable to access")
    soup = BeautifulSoup(response.text, 'html.parser')

    # print(soup.title.string)
    # print(soup.title.parent)
    # print(soup.find_all(id='u_skip'))
    # print(soup.find_all(class_='no_today'))

    # 개발자도구에 selector를 지원함.
    # chart_area > div.rate_info > div > p.no_today > em
    # result = soup.select("div > p.no_today > em > span.blind")
    stock = soup.select_one("div > p.no_today > em > span.blind").text

    name = soup.select_one("#middle > div.h_company > div.wrap_company > h2 > a").text
    print(name, stock)

company_list = ['005380', '005930', '066570']

start = time.time() # 현재 시간 측정
PERIOD_OF_TIME = 10 # 진행 시간 설정

while True :
    # 랜덤 주기로 서버에 요청하기 위한 구문
    time.sleep(randint(1, 2)) # 1~4초 동안 무작위로 쉰다.
    for company in company_list :
        parse_stock(company)
    print("---------------------------")
    if time.time() > start + PERIOD_OF_TIME :
        break

print("Done!")
    
# 주식 종목코드 확인 방법!
# https://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage
```

## 강남구의 면적당 공시지가 크롤링하기
```
import requests
import json

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.368'}
url = "http://openapi.seoul.go.kr:8088/4349786750726d6139356b486b7272/json/IndividuallyPostedLandPriceService/1/100/강남구/%20/%20/%20/%20/2020" # xml이 아닌 json으로 변경해야한다.

# 1. JSON으로 엑셀 데이터 받아오기
# 2. 강남구, 용산구, 서초구, 마포구 데이터 조회해보기
# 3. 100개 읽어오기

# 4. TODO : {강남구 : 100, 용산구 : 80, 서초구 : 90, 마포구 : 60}
# 5. 강남구부터 구현해보고, 나중에 데이터를 연속적으로 읽어오는 코드로 변경해보기

r = requests.get(url, headers = headers)
# print(r) # <Response[200]>이 뜨면 성공
result = r.json()

rows = result['IndividuallyPostedLandPriceService']['row']
# print(rows[0]['JIGA'], len(rows))
sum = 0 
for row in rows :
    sum += int(row['JIGA'])
    
avg = sum/len(rows)  # 평균 공시지가

data_dict = {}
data_dict['강남구'] = avg
print(data_dict)
```

## 네이버 증권 크롤링하기
```
# 네이버 증권에서 원하는 항목의 주가를 파싱해봅시다.
import time
from random import randint # 서버에 주기적으로 요청하면, ip를 막아버리는 경우가 생겨서 random 모듈을 이용한다.
import requests
from bs4 import BeautifulSoup


def parse_stock(company_code) :

    headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.368'}
    url = "https://finance.naver.com/item/main.nhn?code=" + company_code  # SAMSUNG
    
    response = requests.get(url, headers=headers)
    if response.status_code != 200 :
        return print("Unable to access")
    soup = BeautifulSoup(response.text, 'html.parser')

    # print(soup.title.string)
    # print(soup.title.parent)
    # print(soup.find_all(id='u_skip'))
    # print(soup.find_all(class_='no_today'))

    # 개발자도구에 selector를 지원함.
    # chart_area > div.rate_info > div > p.no_today > em
    # result = soup.select("div > p.no_today > em > span.blind")
    stock = soup.select_one("div > p.no_today > em > span.blind").text

    name = soup.select_one("#middle > div.h_company > div.wrap_company > h2 > a").text
    print(name, stock)

company_list = ['005380', '005930', '066570']

start = time.time() # 현재 시간 측정
PERIOD_OF_TIME = 10 # 진행 시간 설정

while True :
    # 랜덤 주기로 서버에 요청하기 위한 구문
    time.sleep(randint(1, 4)) # 1~4초 동안 무작위로 쉰다.
    for company in company_list :
        parse_stock(company)

    if time.time() > start + PERIOD_OF_TIME :
        break

print("Done!")
    
# 주식 종목코드 확인 방법!
# https://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage
```
